# app.py

import streamlit as st
import os
from dotenv import load_dotenv
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
import uuid
import cohere
from groq import Groq

# --- 1. ‡§è‡§®‡§µ‡§æ‡§Ø‡§∞‡§®‡§Æ‡•á‡§Ç‡§ü ‡§î‡§∞ ‡§ï‡•ç‡§≤‡§æ‡§á‡§Ç‡§ü‡•ç‡§∏ ‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡§æ ---

# .env ‡§´‡§º‡§æ‡§á‡§≤ ‡§∏‡•á ‡§µ‡•á‡§∞‡§ø‡§è‡§¨‡§≤‡•ç‡§∏ ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç
load_dotenv()

st.set_page_config(page_title="Mini RAG Final", layout="wide")
st.title("Mini RAG: Ask Your Document üí¨")

# ‡§ï‡•ç‡§∞‡•á‡§°‡•á‡§Ç‡§∂‡§ø‡§Ø‡§≤‡•ç‡§∏
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
COLLECTION_NAME = "mini_rag_collection"

# ‡§∏‡§≠‡•Ä ‡§ï‡•ç‡§≤‡§æ‡§á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§á‡§®‡§ø‡§∂‡§ø‡§Ø‡§≤‡§æ‡§á‡§ú‡§º ‡§î‡§∞ ‡§ï‡•à‡§∂ ‡§ï‡§∞‡•á‡§Ç
@st.cache_resource
def load_clients_and_models():
    if not all([QDRANT_URL, QDRANT_API_KEY, COHERE_API_KEY, GROQ_API_KEY]):
        st.error("‚ö†Ô∏è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§≠‡•Ä API keys ‡§î‡§∞ URL ‡§ï‡•ã .env ‡§´‡§º‡§æ‡§á‡§≤ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§")
        return None, None, None, None
    
    embedding_model = SentenceTransformer('BAAI/bge-small-en-v1.5')
    qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
    cohere_client = cohere.Client(COHERE_API_KEY)
    groq_client = Groq(api_key=GROQ_API_KEY)
    
    return embedding_model, qdrant_client, cohere_client, groq_client

model, qdrant_client, cohere_client, groq_client = load_clients_and_models()

# --- 2. ‡§Ø‡•Ç‡§ú‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ (UI) ---

# UI ‡§ï‡•ã ‡§¶‡•ã ‡§ï‡•â‡§≤‡§Æ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§Ç‡§ü‡•á‡§Ç
col1, col2 = st.columns(2)

with col1:
    st.header("1. Add Document to Knowledge Base")
    input_text = st.text_area("‡§Ø‡§π‡§æ‡§Å ‡§Ö‡§™‡§®‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§™‡•á‡§∏‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç:", height=250, key="text_input")
    
    if st.button("Process & Store"):
        if input_text.strip() and all([model, qdrant_client]):
            with st.spinner("‚è≥ Processing and storing text..."):
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150, length_function=len)
                chunks = text_splitter.split_text(input_text)
                
                qdrant_client.upsert(
                    collection_name=COLLECTION_NAME,
                    points=[
                        models.PointStruct(
                            id=str(uuid.uuid4()),
                            vector=model.encode(chunk).tolist(),
                            payload={"text": chunk}
                        ) for chunk in chunks
                    ],
                    wait=True
                )
                st.success("‚úÖ Document processed and stored successfully!")
                st.session_state.document_processed = True

with col2:
    st.header("2. Ask a Question")
    query = st.text_input("‡§Ö‡§™‡§®‡•á ‡§°‡•â‡§ï‡•ç‡§Ø‡•Ç‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç:", key="query_input")

    if st.button("Get Answer"):
        if not query.strip():
            st.warning("‚ö†Ô∏è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§")
        elif not all([model, qdrant_client, cohere_client, groq_client]):
             st.error("Clients are not initialized. Please check your credentials.")
        else:
            with st.spinner("‚è≥ Finding the best answer..."):
                # --- 3. RAG ‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§ï‡§æ ‡§≤‡•â‡§ú‡§ø‡§ï ---
                
                # a. Retrieve: Qdrant ‡§∏‡•á ‡§Æ‡§ø‡§≤‡§§‡•á-‡§ú‡•Å‡§≤‡§§‡•á ‡§ö‡§Ç‡§ï‡•ç‡§∏ ‡§ñ‡•ã‡§ú‡•á‡§Ç
                query_vector = model.encode(query).tolist()
                retrieved_hits = qdrant_client.search(
                    collection_name=COLLECTION_NAME,
                    query_vector=query_vector,
                    limit=10  # 10 ‡§∏‡§¨‡§∏‡•á ‡§Æ‡§ø‡§≤‡§§‡•á-‡§ú‡•Å‡§≤‡§§‡•á ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü‡•ç‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç
                )
                retrieved_docs = [hit.payload['text'] for hit in retrieved_hits]

                # b. Rerank: Cohere ‡§∏‡•á ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§î‡§∞ ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ‡§è‡§Å
                reranked_docs = cohere_client.rerank(
                    model='rerank-english-v3.0',
                    query=query,
                    documents=retrieved_docs,
                    top_n=3  # 3 ‡§∏‡§¨‡§∏‡•á ‡§∏‡§ü‡•Ä‡§ï ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü‡•ç‡§∏ ‡§ö‡•Å‡§®‡•á‡§Ç
                )

                context_docs = [retrieved_docs[doc.index] for doc in reranked_docs.results]
                
                # c. Answer: Groq LLM ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§¨‡§®‡§æ‡§è‡§Å
                context_for_prompt = "\n\n".join([f"[source_{i+1}]: {doc}" for i, doc in enumerate(context_docs)])
                
                prompt = f"""
                You are an expert Q&A system. Your answer must be grounded in the provided context.
                Answer the user's question based ONLY on the following context.
                For each statement, you MUST cite the source using the format [source_N].
                If the context does not contain the answer, reply with "I cannot answer this question based on the provided text."

                Context:
                {context_for_prompt}

                Question: {query}
                Answer:
                """

                chat_completion = groq_client.chat.completions.create(
                    messages=[{"role": "user", "content": prompt}],
                    model="llama-3.1-8b-instant",
                )
                final_answer = chat_completion.choices[0].message.content

                # --- 4. ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü‡•ç‡§∏ ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Å ---
                st.subheader("Answer:")
                st.markdown(final_answer)
                
                with st.expander("üìö See Sources"):
                    for i, doc in enumerate(context_docs):
                        st.markdown(f"**Source {i+1}:**")
                        st.info(doc)